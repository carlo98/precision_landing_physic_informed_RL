# General
action_space: 3  # Number of actions: 2 or 3, i.e. (vx, vy) or (vx, vy, vz)
obs_shape: 6  # 5 or 6, add vz
num_env_episodes: 6009  # Keep it a multiple of evaluate_freq and add evaluate_ep at the end
train_freq: 1  # In episodes
num-steps: 350  # Max steps for each episode
seed: 5  # Random seed
max_memory_len: 35000  # 100 episodes
mem_to_use: 8192  # Try to keep this a multiple of the batch size
min_mem: 1024  # Minimal memory to use
log_interval_episodes: 100
max_height: 3.5  # Max height of cube in which the agent can move
min_height: 1.8  # Min height at which the agent can spawn
max_side: 5.0  # Side of square in which the agent can move
max_vel_xy: 1.0  # Max velocity of agent in x and y axis
max_vel_z: 1.0  # Max velocity of agent in z-axis
max_vel_target: 0.8  # Max velocity of target
min_vel_target: 0.4  # Min velocity of target
trajectory: "still"  # Target movements: "linear" or "circular" or "still"
train_window_reward: 100
test_window_reward: 3
evaluate_freq: 500
evaluate_ep: 9  # Keep this a multiple of test_window_reward
eval_noise: 0.2  # std for gaussian evaluation noise
model: "small"  # "paper" or "small" or "small_one_head"
eps_pos_xy: 0.3  # Target dimension

# DDPG
epochs: 1
batch_size: 64
gamma: 0.99
tau: 0.001
lr_actor: 0.0001
lr_critic: 0.001
